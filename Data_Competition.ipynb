{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7zWgoG1OfYf_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KidPool2411/Data-Competition/blob/main/Data_Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHn5aNLg23vp"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DEpMpgsX-MU3-de4Gqoa7Nk3VD12_Vwk)\n",
        "\n",
        "# üìåüìåüìå This is a notebook for the [Data-Competition](https://github.com/fsoft-ailab/Data-Competition), which is hosted by FPT Software's AILab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/yolomask'\n",
        "\n",
        "def isfile(path):\n",
        "  import os\n",
        "  return os.path.isfile(path)\n",
        "def isdir(path):\n",
        "  import os\n",
        "  return os.path.isdir(path)\n",
        "\n",
        "def cd(path=''):\n",
        "  combined_path = f'{base_path}/{path}'\n",
        "  if(isdir(combined_path) == False):\n",
        "      %mkdir '{combined_path}'\n",
        "\n",
        "  %cd '{combined_path}'\n",
        "\n",
        "def cd_rm(path=''):\n",
        "  !rm -rf \"{path}\"\n",
        "  cd(path)\n",
        "\n",
        "def get_file_name(path):\n",
        "  from pathlib import Path\n",
        "\n",
        "  return Path(path).stem\n",
        "\n",
        "\n",
        "def zip_and_download(path):\n",
        "  filename = get_file_name(path)\n",
        "  zip_path = f'{path}.zip'\n",
        "\n",
        "  !rm -rf \"{zip_path}\"\n",
        "  !zip -r '{zip_path}' '{path}'\n",
        "\n",
        "  download(zip_path)\n",
        "\n",
        "def gdownload(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "def gdownload_and_unzip(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "  !unzip '{filename}'\n",
        "  os.remove(f'{output}')\n",
        "\n",
        "if(isdir(base_path) == False):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eGnd4JZvp2h",
        "outputId": "962fbdcc-9f96-40d1-e4c5-7841243350ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CzjUFqhJv33h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zWgoG1OfYf_"
      },
      "source": [
        "# ‚öôÔ∏è Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihGOYm8DfJsl",
        "outputId": "614b95b2-a9d0-4c6d-9278-c3e73f7bf98a"
      },
      "source": [
        "cd()\n",
        "\n",
        "if(isdir(\"Data-Competition\") == False):\n",
        "  !git clone https://github.com/fsoft-ailab/Data-Competition # clone repo\n",
        "  cd(\"Data-Competition\")\n",
        "  !pip3 install -r requirements.txt # install dependencies\n",
        "\n",
        "  import torch\n",
        "  from IPython.display import Image, clear_output\n",
        "\n",
        "  clear_output()\n",
        "  print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.10.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Web_mcnefe5k"
      },
      "source": [
        "\n",
        "# üìÇ Download Dataset\n",
        "\n",
        "\n",
        "\n",
        "> üî∞ Download the original dataset. If you want to use your own data, upload it to google drive and replace the file's id in the scripts below.\n",
        "\n",
        "\n",
        "> üî∞ We suggest following the organizer's structure. This will be convenient during the procedure.\n",
        "\n",
        "\n",
        "üí° If you do not know how to get the file's id, click [here](https://www.swipetips.com/how-to-determine-the-file-id-of-a-content-in-google-drive/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSlDXj8__228"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "if(isdir(\"dataset\") == False):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  id = '1GunQVFl7UU5DpfdTw5daocEptamtvrjO' # file's id (change your file's id)\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  output = './dataset.zip'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "  !unzip dataset.zip\n",
        "  os.remove('./dataset.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQN8y0CnVMv"
      },
      "source": [
        "# üî¨ Trainning \n",
        "\n",
        "\n",
        "\n",
        "> üî∞ We configured all the parameters for training\n",
        "\n",
        "\n",
        "> üî∞ If the structure of the dataset is not the same as the organizer, you can change the path in `config/data_cfg.yaml`\n",
        "\n",
        "\n",
        "‚ùó‚ùó You should not change such hyperparameters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mD4kdBZCBtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7786f14-e382-456d-a97a-de8a2c04b81d"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "!python train.py --name test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 18.3MB/s]\n",
            "\u001b[34m\u001b[1mTrain: \u001b[0mdata_cfg=config/data_cfg.yaml, batch_size=64, cache=None, device=, workers=8, name=test, weights=pretrains/pretrain.pt, model_cfg=models/yolov5s.yaml, hyp=config/hyps/hyp_finetune.yaml, project=results/train, artifact_alias=latest, epochs=100, img_size=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=False, bucket=, image_weights=False, multi_scale=False, single_cls=False, adam=False, sync_bn=False, entity=, exist_ok=False, quad=False, label_smoothing=0.0, linear_lr=False, bbox_interval=-1, save_period=-1, patience=100\n",
            "YOLOv5 üöÄ 63741b6 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "cuda:0\n",
            "\u001b[34m\u001b[1mHyper parameters: \u001b[0mlr0=0.0032, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir results/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 283 layers, 7068936 parameters, 7068936 gradients, 16.4 GFLOPs\n",
            "\n",
            "Transferred 360/362 items from pretrains/pretrain.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1mOptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
            "\u001b[34m\u001b[1mTrain: \u001b[0mScanning 'dataset/labels/train' images and labels...792 found, 0 missing, 2 empty, 0 corrupted: 100% 792/792 [00:03<00:00, 245.62it/s]\n",
            "\u001b[34m\u001b[1mTrain: \u001b[0mNew cache created: dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1mVal: \u001b[0mScanning 'dataset/labels/val' images and labels...184 found, 0 missing, 1 empty, 0 corrupted: 100% 184/184 [00:01<00:00, 148.44it/s]\n",
            "\u001b[34m\u001b[1mVal: \u001b[0mNew cache created: dataset/labels/val.cache\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.82, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mresults/train/test\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99     11.3G   0.05516   0.01263   0.01647        32       640: 100% 13/13 [01:19<00:00,  6.10s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.80s/it]\n",
            "                 all        184        285      11831      0.878      0.425      0.381      0.491      0.209\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99     11.3G   0.05069   0.01064   0.01343        32       640: 100% 13/13 [01:16<00:00,  5.90s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285      17243      0.888      0.435      0.386        0.5      0.208\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99     11.3G   0.04643  0.009548  0.009118        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.19s/it]\n",
            "                 all        184        285      18318      0.757      0.429      0.367      0.464      0.199\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99     11.3G    0.0426  0.009026  0.007323        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all        184        285      14867      0.773      0.343       0.33      0.414      0.173\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99     11.3G   0.04194  0.008917  0.007684        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.22s/it]\n",
            "                 all        184        285      19254      0.795       0.38      0.315      0.412      0.158\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99     11.3G   0.04115  0.008769   0.00793        32       640: 100% 13/13 [01:15<00:00,  5.81s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
            "                 all        184        285      16445      0.774      0.346      0.275      0.356      0.132\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99     11.3G   0.04116  0.008876  0.007983        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all        184        285      13234      0.743      0.301      0.264      0.347      0.128\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99     11.3G   0.03912   0.00867  0.006478        32       640: 100% 13/13 [01:15<00:00,  5.81s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285       6917      0.432      0.464      0.276      0.365      0.124\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99     11.3G   0.03987  0.008133  0.005912        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
            "                 all        184        285       7270      0.476      0.494      0.336      0.436      0.162\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99     11.3G   0.03801  0.007647  0.006012        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all        184        285       6777      0.471      0.471      0.326      0.431      0.163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99     11.3G   0.03703  0.007525  0.005906        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
            "                 all        184        285       8905      0.432       0.45        0.3      0.404      0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99     11.3G   0.03736  0.007637   0.00603        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285      15097      0.403      0.431      0.312      0.415      0.139\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99     11.3G   0.03548   0.00783  0.006905        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
            "                 all        184        285      13740      0.757      0.416      0.316      0.418      0.139\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99     11.3G   0.03756  0.007914  0.005137        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
            "                 all        184        285      11983      0.824      0.406      0.341      0.442      0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99     11.3G   0.03312  0.007153  0.004264        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.21s/it]\n",
            "                 all        184        285       5857      0.564       0.44      0.313      0.417       0.15\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99     11.3G   0.03266  0.006954  0.003416        32       640: 100% 13/13 [01:15<00:00,  5.82s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285       6106      0.796       0.43      0.341      0.451      0.152\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99     11.3G   0.03331  0.006386  0.003263        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
            "                 all        184        285       5587      0.485      0.576      0.369      0.468      0.143\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99     11.3G   0.03211  0.006234  0.003011        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
            "                 all        184        285       6270      0.493      0.538      0.369      0.459      0.141\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99     11.3G   0.03196  0.006032  0.002788        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.10s/it]\n",
            "                 all        184        285       5684      0.812      0.448      0.344      0.457      0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99     11.3G   0.02954  0.005947    0.0027        32       640: 100% 13/13 [01:15<00:00,  5.82s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
            "                 all        184        285       6049      0.873      0.382      0.335       0.45       0.15\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99     11.3G   0.03108   0.00594  0.002458        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
            "                 all        184        285       6260      0.452      0.489      0.323      0.436      0.149\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99     11.3G   0.03224  0.005951   0.00285        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.18s/it]\n",
            "                 all        184        285       6853      0.767      0.447      0.312      0.427       0.15\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99     11.3G    0.0311  0.005665  0.002516        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
            "                 all        184        285       5861      0.379      0.581      0.332      0.438      0.153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99     11.3G   0.03019  0.005768  0.002409        32       640: 100% 13/13 [01:15<00:00,  5.81s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
            "                 all        184        285       8013      0.434      0.519      0.321      0.422      0.135\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99     11.3G   0.02796   0.00553  0.002247        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285       6866      0.426      0.489      0.322      0.423      0.129\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99     11.3G   0.03353  0.005476   0.00227        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.20s/it]\n",
            "                 all        184        285       7234      0.518      0.494      0.356      0.459      0.164\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99     11.3G   0.03288  0.005591  0.002226        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.15s/it]\n",
            "                 all        184        285       7523      0.576      0.523      0.383      0.495       0.18\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99     11.3G   0.03001  0.005507  0.002138        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.13s/it]\n",
            "                 all        184        285       6856      0.857      0.423      0.349      0.468      0.161\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99     11.3G   0.02814  0.005454  0.002028        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
            "                 all        184        285       4964      0.918      0.389      0.355      0.479      0.165\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99     11.3G   0.02762  0.005398  0.002025        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
            "                 all        184        285       5159      0.839      0.391      0.319      0.435      0.149\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99     11.3G   0.02782  0.005306  0.001955        32       640: 100% 13/13 [01:15<00:00,  5.79s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.21s/it]\n",
            "                 all        184        285       4828      0.773      0.423      0.318      0.429      0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/99     11.3G   0.02801  0.005278  0.001912        32       640: 100% 13/13 [01:15<00:00,  5.80s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
            "                 all        184        285       5118      0.774      0.422      0.313      0.428      0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/99     11.3G   0.02768  0.005123  0.001915        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.17s/it]\n",
            "                 all        184        285       5518      0.468      0.414      0.332       0.44      0.154\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/99     11.3G   0.02682   0.00511  0.001905        32       640: 100% 13/13 [01:15<00:00,  5.78s/it]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.12s/it]\n",
            "                 all        184        285       5403      0.443      0.486       0.33      0.438      0.162\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/99     11.3G   0.02615  0.004891   0.00193        95       640:  62% 8/13 [00:48<00:30,  6.06s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZoDLd6jpWbD"
      },
      "source": [
        "# ‚úç Evaluation\n",
        "\n",
        "\n",
        "> üî∞ val.py evaluates a model on a particular dataset. There are three different types of mAP@.5. To rank, we use wAP and the formula mentioned on [github](https://github.com/fsoft-ailab/Data-Competition#model--metrics-).\n",
        "\n",
        "\n",
        "\n",
        "> üî∞ The results are saved in ***results/evaluate*** once the process is finished.\n",
        "\n",
        "\n",
        "\n",
        "```shell\n",
        "python3 val.py --weights <path_to_weight> --task test --name <version_name> --batch-size 64 --device 0\n",
        "                                                 val\n",
        "                                                 train\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GcItgqQCVCX"
      },
      "source": [
        "!python val.py --weights results/train/test/weights/best.pt --task test --name test --device 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69npbzNLpZ-V"
      },
      "source": [
        "# üîç Detection\n",
        "\n",
        "\n",
        "\n",
        "> üî∞  The model can be inferred from two sources: an image or a folder of images.\n",
        "\n",
        "\n",
        "\n",
        "> üî∞  If you want to get bounding box, hide conf, ... look for argument in `detect.py`\n",
        "\n",
        "```shell\n",
        "python detect.py --weights <your_weights> --source <path_to_image>\n",
        "                                                   <path_to_folder>\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcDa0NRwQl0m"
      },
      "source": [
        "!python detect.py --weights results/train/test/weights/best.pt --source dataset/images/public_test --dir ./detect_public_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIc3QQtUh7G"
      },
      "source": [
        "Image(filename='detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg', width=1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}