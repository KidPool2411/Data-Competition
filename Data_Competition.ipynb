{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7zWgoG1OfYf_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KidPool2411/Data-Competition/blob/main/Data_Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHn5aNLg23vp"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DEpMpgsX-MU3-de4Gqoa7Nk3VD12_Vwk)\n",
        "\n",
        "# ðŸ“ŒðŸ“ŒðŸ“Œ This is a notebook for the [Data-Competition](https://github.com/fsoft-ailab/Data-Competition), which is hosted by FPT Software's AILab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/yolomask'\n",
        "\n",
        "def isfile(path):\n",
        "  import os\n",
        "  return os.path.isfile(path)\n",
        "def isdir(path):\n",
        "  import os\n",
        "  return os.path.isdir(path)\n",
        "\n",
        "def cd(path=''):\n",
        "  combined_path = f'{base_path}/{path}'\n",
        "  if(isdir(combined_path) == False):\n",
        "      %mkdir '{combined_path}'\n",
        "\n",
        "  %cd '{combined_path}'\n",
        "\n",
        "def cd_rm(path=''):\n",
        "  !rm -rf \"{path}\"\n",
        "  cd(path)\n",
        "\n",
        "def get_file_name(path):\n",
        "  from pathlib import Path\n",
        "\n",
        "  return Path(path).stem\n",
        "\n",
        "\n",
        "def zip_and_download(path):\n",
        "  filename = get_file_name(path)\n",
        "  zip_path = f'{path}.zip'\n",
        "\n",
        "  !rm -rf \"{zip_path}\"\n",
        "  !zip -r '{zip_path}' '{path}'\n",
        "\n",
        "  download(zip_path)\n",
        "\n",
        "def gdownload(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "def gdownload_and_unzip(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  filename = f'{filename}.zip'\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "  !unzip '{filename}'\n",
        "  os.remove(f'{output}')\n",
        "\n",
        "def read_file(path):\n",
        "  with open(path, 'r') as f:\n",
        "    return f.read()\n",
        "\n",
        "def write_file(path, text):\n",
        "  with open(path, 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "if(isdir(base_path) == False):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "cd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eGnd4JZvp2h",
        "outputId": "fd5e2621-5f1f-4e44-f1a2-d88c20dac967"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CzjUFqhJv33h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zWgoG1OfYf_"
      },
      "source": [
        "# âš™ï¸ Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihGOYm8DfJsl",
        "outputId": "614b95b2-a9d0-4c6d-9278-c3e73f7bf98a"
      },
      "source": [
        "cd()\n",
        "\n",
        "if(isdir(\"Data-Competition\") == False):\n",
        "  !git clone https://github.com/fsoft-ailab/Data-Competition # clone repo\n",
        "  cd(\"Data-Competition\")\n",
        "  !pip3 install -r requirements.txt # install dependencies\n",
        "\n",
        "  import torch\n",
        "  from IPython.display import Image, clear_output\n",
        "\n",
        "  clear_output()\n",
        "  print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.10.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Web_mcnefe5k"
      },
      "source": [
        "\n",
        "# ðŸ“‚ Download Dataset\n",
        "\n",
        "\n",
        "\n",
        "> ðŸ”° Download the original dataset. If you want to use your own data, upload it to google drive and replace the file's id in the scripts below.\n",
        "\n",
        "\n",
        "> ðŸ”° We suggest following the organizer's structure. This will be convenient during the procedure.\n",
        "\n",
        "\n",
        "ðŸ’¡ If you do not know how to get the file's id, click [here](https://www.swipetips.com/how-to-determine-the-file-id-of-a-content-in-google-drive/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSlDXj8__228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621d40da-e89b-4593-9527-300f7e704f4a"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "dataset = 'dataset_source_v3'\n",
        "id = '1xJvsPD4SKpJHRmcGDtvdOAl1DU4Nr-Uc' # file's id (change your file's id)\n",
        "\n",
        "if(isdir(dataset) == False):  \n",
        "  gdownload_and_unzip(id, dataset)\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  cd(\"Data-Competition\")\n",
        "  \n",
        "  original_data_cfg = read_file(\"config/original_data_cfg.yaml\")\n",
        "  write_file(\"config/data_cfg.yaml\", original_data_cfg.replace(\"/dataset\", \"/\" + dataset))"
      ],
      "metadata": {
        "id": "FfqXmxg136-I",
        "outputId": "5de59046-615b-4b9d-c7ab-eedf283c2864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQN8y0CnVMv"
      },
      "source": [
        "# ðŸ”¬ Trainning \n",
        "\n",
        "\n",
        "\n",
        "> ðŸ”° We configured all the parameters for training\n",
        "\n",
        "\n",
        "> ðŸ”° If the structure of the dataset is not the same as the organizer, you can change the path in `config/data_cfg.yaml`\n",
        "\n",
        "\n",
        "â—â— You should not change such hyperparameters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mD4kdBZCBtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d23da9-9606-45c3-bdc4-fe46919d9628"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "!python train.py --name test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n",
            "\u001b[34m\u001b[1mTrain: \u001b[0mdata_cfg=config/data_cfg.yaml, batch_size=64, cache=None, device=, workers=8, name=test, weights=pretrains/pretrain.pt, model_cfg=models/yolov5s.yaml, hyp=config/hyps/hyp_finetune.yaml, project=results/train, artifact_alias=latest, epochs=100, img_size=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=False, bucket=, image_weights=False, multi_scale=False, single_cls=False, adam=False, sync_bn=False, entity=, exist_ok=False, quad=False, label_smoothing=0.0, linear_lr=False, bbox_interval=-1, save_period=-1, patience=100\n",
            "YOLOv5 ðŸš€ 63741b6 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "cuda:0\n",
            "\u001b[34m\u001b[1mHyper parameters: \u001b[0mlr0=0.0032, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, degrees=0.0, translate=0.0, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir results/train', view at http://localhost:6006/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZoDLd6jpWbD"
      },
      "source": [
        "# âœ Evaluation\n",
        "\n",
        "\n",
        "> ðŸ”° val.py evaluates a model on a particular dataset. There are three different types of mAP@.5. To rank, we use wAP and the formula mentioned on [github](https://github.com/fsoft-ailab/Data-Competition#model--metrics-).\n",
        "\n",
        "\n",
        "\n",
        "> ðŸ”° The results are saved in ***results/evaluate*** once the process is finished.\n",
        "\n",
        "\n",
        "\n",
        "```shell\n",
        "python3 val.py --weights <path_to_weight> --task test --name <version_name> --batch-size 64 --device 0\n",
        "                                                 val\n",
        "                                                 train\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights pretrains/pretrain.pt --task test --name pretrain --device 0"
      ],
      "metadata": {
        "id": "G6_J6WVfkRBT",
        "outputId": "0446b195-4f97-4806-9e6b-1f3d0846a4fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=config/data_cfg.yaml, weights=pretrains/pretrain.pt, task=test, name=pretrain, batch_size=64, device=0, img_size=640, conf_threshold=0.001, iou_threshold=0.6, augment=False, exist_ok=False, half=False, project=results/evaluate/test, save_conf=False, save_hybrid=False, save_txt=False, verbose=False, plots=True\n",
            "YOLOv5 ðŸš€ 2021-12-21 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'dataset/labels/public_test.cache' images and labels... 88 found, 0 missing, 0 empty, 0 corrupted: 100% 88/88 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.84s/it]\n",
            "                 all         88        148       1500      0.344      0.585      0.376      0.442      0.187\n",
            "             no_mask         42         42        578      0.391      0.571      0.508      0.508      0.181\n",
            "                mask         92         92        689      0.427      0.685      0.619      0.619      0.295\n",
            "      incorrect_mask         14         14        233      0.213        0.5        0.2        0.2     0.0838\n",
            "Speed: 0.3ms pre-process, 19.6ms inference, 4.1ms NMS per image at shape (24, 3, 640, 640)\n",
            "Results saved to \u001b[1mresults/evaluate/test/pretrain\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GcItgqQCVCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82760fc6-19ea-4498-954b-39690377d23f"
      },
      "source": [
        "!python val.py --weights results/train/test/weights/best.pt --task test --name test --device 0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=config/data_cfg.yaml, weights=results/train/test/weights/best.pt, task=test, name=test, batch_size=64, device=0, img_size=640, conf_threshold=0.001, iou_threshold=0.6, augment=False, exist_ok=False, half=False, project=results/evaluate/test, save_conf=False, save_hybrid=False, save_txt=False, verbose=False, plots=True\n",
            "YOLOv5 ðŸš€ 2021-12-21 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'dataset/labels/public_test' images and labels...88 found, 0 missing, 0 empty, 0 corrupted: 100% 88/88 [00:00<00:00, 255.36it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: dataset/labels/public_test.cache\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.96s/it]\n",
            "                 all         88        148       1915      0.429      0.514      0.381      0.452      0.155\n",
            "             no_mask         42         42        554      0.409      0.643      0.523      0.523      0.155\n",
            "                mask         92         92       1023      0.556      0.685       0.64       0.64      0.226\n",
            "      incorrect_mask         14         14        338      0.323      0.214      0.191      0.191     0.0853\n",
            "Speed: 0.3ms pre-process, 20.5ms inference, 4.0ms NMS per image at shape (24, 3, 640, 640)\n",
            "Results saved to \u001b[1mresults/evaluate/test/test\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69npbzNLpZ-V"
      },
      "source": [
        "# ðŸ” Detection\n",
        "\n",
        "\n",
        "\n",
        "> ðŸ”°  The model can be inferred from two sources: an image or a folder of images.\n",
        "\n",
        "\n",
        "\n",
        "> ðŸ”°  If you want to get bounding box, hide conf, ... look for argument in `detect.py`\n",
        "\n",
        "```shell\n",
        "python detect.py --weights <your_weights> --source <path_to_image>\n",
        "                                                   <path_to_folder>\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcDa0NRwQl0m"
      },
      "source": [
        "!python detect.py --weights results/train/test/weights/best.pt --source dataset/images/public_test --dir ./detect_public_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "24XxLRINkPKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIc3QQtUh7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "2e43e147-c962-4960-ca1c-3ce551278a2f"
      },
      "source": [
        "Image(filename='detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg', width=1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6b606b217b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg'"
          ]
        }
      ]
    }
  ]
}