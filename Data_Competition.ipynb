{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data-Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7zWgoG1OfYf_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KidPool2411/Data-Competition/blob/main/Data_Competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHn5aNLg23vp"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1DEpMpgsX-MU3-de4Gqoa7Nk3VD12_Vwk)\n",
        "\n",
        "# 📌📌📌 This is a notebook for the [Data-Competition](https://github.com/fsoft-ailab/Data-Competition), which is hosted by FPT Software's AILab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/yolomask'\n",
        "\n",
        "def isfile(path):\n",
        "  import os\n",
        "  return os.path.isfile(path)\n",
        "def isdir(path):\n",
        "  import os\n",
        "  return os.path.isdir(path)\n",
        "\n",
        "def cd(path=''):\n",
        "  combined_path = f'{base_path}/{path}'\n",
        "  if(isdir(combined_path) == False):\n",
        "      %mkdir '{combined_path}'\n",
        "\n",
        "  %cd '{combined_path}'\n",
        "\n",
        "def cd_rm(path=''):\n",
        "  !rm -rf \"{path}\"\n",
        "  cd(path)\n",
        "\n",
        "def get_file_name(path):\n",
        "  from pathlib import Path\n",
        "\n",
        "  return Path(path).stem\n",
        "\n",
        "\n",
        "def zip_and_download(path):\n",
        "  filename = get_file_name(path)\n",
        "  zip_path = f'{path}.zip'\n",
        "\n",
        "  !rm -rf \"{zip_path}\"\n",
        "  !zip -r '{zip_path}' '{path}'\n",
        "\n",
        "  download(zip_path)\n",
        "\n",
        "def gdownload(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "def gdownload_and_unzip(id, filename):\n",
        "  import gdown\n",
        "  import os\n",
        "\n",
        "  url = 'https://drive.google.com/u/1/uc?id={}&export=download'.format(id)\n",
        "  filename = f'{filename}.zip'\n",
        "  output = f'./{filename}'\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "  !unzip '{filename}'\n",
        "  os.remove(f'{output}')\n",
        "\n",
        "def read_file(path):\n",
        "  with open(path, 'r') as f:\n",
        "    return f.read()\n",
        "\n",
        "def write_file(path, text):\n",
        "  with open(path, 'w') as f:\n",
        "    f.write(text)\n",
        "\n",
        "if(isdir(base_path) == False):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "cd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eGnd4JZvp2h",
        "outputId": "fd5e2621-5f1f-4e44-f1a2-d88c20dac967"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CzjUFqhJv33h"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zWgoG1OfYf_"
      },
      "source": [
        "# ⚙️ Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihGOYm8DfJsl",
        "outputId": "614b95b2-a9d0-4c6d-9278-c3e73f7bf98a"
      },
      "source": [
        "cd()\n",
        "\n",
        "if(isdir(\"Data-Competition\") == False):\n",
        "  !git clone https://github.com/fsoft-ailab/Data-Competition # clone repo\n",
        "  cd(\"Data-Competition\")\n",
        "  !pip3 install -r requirements.txt # install dependencies\n",
        "\n",
        "  import torch\n",
        "  from IPython.display import Image, clear_output\n",
        "\n",
        "  clear_output()\n",
        "  print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.10.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Web_mcnefe5k"
      },
      "source": [
        "\n",
        "# 📂 Download Dataset\n",
        "\n",
        "\n",
        "\n",
        "> 🔰 Download the original dataset. If you want to use your own data, upload it to google drive and replace the file's id in the scripts below.\n",
        "\n",
        "\n",
        "> 🔰 We suggest following the organizer's structure. This will be convenient during the procedure.\n",
        "\n",
        "\n",
        "💡 If you do not know how to get the file's id, click [here](https://www.swipetips.com/how-to-determine-the-file-id-of-a-content-in-google-drive/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSlDXj8__228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621d40da-e89b-4593-9527-300f7e704f4a"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "dataset = 'dataset_source_v2'\n",
        "id = '1PjNm702qVvT75wRx7AEP8bKnu8jyfv6K' # file's id (change your file's id)\n",
        "\n",
        "if(isdir(dataset) == False):  \n",
        "  gdownload_and_unzip(id, dataset)\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "original_data_cfg = read_file(\"config/original_data_cfg.yaml\")\n",
        "original_data_cfg = original_data_cfg.replace(\"/dataset/images/train\", f'/{dataset}/images/train')\n",
        "original_data_cfg = original_data_cfg.replace(\"/dataset/images/val\", f'/{dataset}/images/val')\n",
        "print(original_data_cfg)\n",
        "write_file(\"config/data_cfg.yaml\", original_data_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfqXmxg136-I",
        "outputId": "89d47e53-16bf-4f33-a00c-f2cd2fcdfd6b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/yolomask/Data-Competition\n",
            "train: ./dataset_source_v3/images/train  # relative path to train images\n",
            "val: ./dataset_source_v3/images/val  # relative path to val images\n",
            "test: ./dataset/images/public_test  # relative path to public test images\n",
            "\n",
            "# Classes\n",
            "# Please don't change\n",
            "num_class: 3  # number of classes\n",
            "# names: ['0', '1', '2']\n",
            "names: ['no_mask', 'mask', 'incorrect_mask']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_data_cfg"
      ],
      "metadata": {
        "id": "1GUctgg4LIUy",
        "outputId": "a3a1a90e-19e7-447d-c34a-d1953e91b62d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train: ./dataset/images/train  # relative path to train images\\nval: ./dataset/images/val  # relative path to val images\\ntest: ./dataset/images/public_test  # relative path to public test images\\n\\n# Classes\\n# Please don't change\\nnum_class: 3  # number of classes\\n# names: ['0', '1', '2']\\nnames: ['no_mask', 'mask', 'incorrect_mask']\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_data_cfg.replace(\"/dataset/images/val\", f'/{dataset}/images/val')"
      ],
      "metadata": {
        "id": "hdzVOd-zLDpT",
        "outputId": "3edd6328-39ea-4252-c929-8d25f99a89db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"train: ./dataset/images/train  # relative path to train images\\nval: ./dataset_source_v3/images/val  # relative path to val images\\ntest: ./dataset/images/public_test  # relative path to public test images\\n\\n# Classes\\n# Please don't change\\nnum_class: 3  # number of classes\\n# names: ['0', '1', '2']\\nnames: ['no_mask', 'mask', 'incorrect_mask']\\n\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQQN8y0CnVMv"
      },
      "source": [
        "# 🔬 Trainning \n",
        "\n",
        "\n",
        "\n",
        "> 🔰 We configured all the parameters for training\n",
        "\n",
        "\n",
        "> 🔰 If the structure of the dataset is not the same as the organizer, you can change the path in `config/data_cfg.yaml`\n",
        "\n",
        "\n",
        "❗❗ You should not change such hyperparameters\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mD4kdBZCBtT"
      },
      "source": [
        "cd(\"Data-Competition\")\n",
        "\n",
        "!python train.py --name '{dataset}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZoDLd6jpWbD"
      },
      "source": [
        "# ✍ Evaluation\n",
        "\n",
        "\n",
        "> 🔰 val.py evaluates a model on a particular dataset. There are three different types of mAP@.5. To rank, we use wAP and the formula mentioned on [github](https://github.com/fsoft-ailab/Data-Competition#model--metrics-).\n",
        "\n",
        "\n",
        "\n",
        "> 🔰 The results are saved in ***results/evaluate*** once the process is finished.\n",
        "\n",
        "\n",
        "\n",
        "```shell\n",
        "python3 val.py --weights <path_to_weight> --task test --name <version_name> --batch-size 64 --device 0\n",
        "                                                 val\n",
        "                                                 train\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights pretrains/pretrain.pt --task test --name pretrain --device 0"
      ],
      "metadata": {
        "id": "G6_J6WVfkRBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights results/train/test/weights/best.pt --task test --name pretrain --device 0"
      ],
      "metadata": {
        "id": "BbdFtU35KBgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GcItgqQCVCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51d1e59b-1a79-46a0-c6cd-418b957fa1f7"
      },
      "source": [
        "!python val.py --weights results/train/test3/weights/best.pt --task test --name '{dataset}' --device 0"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=config/data_cfg.yaml, weights=results/train/test3/weights/best.pt, task=test, name=dataset_source_v3, batch_size=64, device=0, img_size=640, conf_threshold=0.001, iou_threshold=0.6, augment=False, exist_ok=False, half=False, project=results/evaluate/test, save_conf=False, save_hybrid=False, save_txt=False, verbose=False, plots=True\n",
            "YOLOv5 🚀 2021-12-21 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 224 layers, 7059304 parameters, 0 gradients, 16.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'dataset/labels/public_test.cache' images and labels... 88 found, 0 missing, 0 empty, 0 corrupted: 100% 88/88 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels      Boxes          P          R     wAP@.5     mAP@.5 mAP@.5:.95: 100% 2/2 [00:05<00:00,  2.76s/it]\n",
            "                 all         88        148       1719      0.992      0.967       0.99      0.989      0.688\n",
            "             no_mask         42         42        477          1      0.905      0.977      0.977      0.616\n",
            "                mask         92         92        775      0.989      0.995      0.995      0.995      0.697\n",
            "      incorrect_mask         14         14        467      0.988          1      0.995      0.995      0.751\n",
            "Speed: 2.6ms pre-process, 16.0ms inference, 3.2ms NMS per image at shape (24, 3, 640, 640)\n",
            "Results saved to \u001b[1mresults/evaluate/test/dataset_source_v33\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69npbzNLpZ-V"
      },
      "source": [
        "# 🔍 Detection\n",
        "\n",
        "\n",
        "\n",
        "> 🔰  The model can be inferred from two sources: an image or a folder of images.\n",
        "\n",
        "\n",
        "\n",
        "> 🔰  If you want to get bounding box, hide conf, ... look for argument in `detect.py`\n",
        "\n",
        "```shell\n",
        "python detect.py --weights <your_weights> --source <path_to_image>\n",
        "                                                   <path_to_folder>\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcDa0NRwQl0m"
      },
      "source": [
        "!python detect.py --weights results/train/test/weights/best.pt --source dataset/images/public_test --dir ./detect_public_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "24XxLRINkPKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxIc3QQtUh7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "2e43e147-c962-4960-ca1c-3ce551278a2f"
      },
      "source": [
        "Image(filename='detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg', width=1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6b606b217b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'detect_public_test/10.35.17.162_01_20210715165612157_MOTION_DETECTION.jpg'"
          ]
        }
      ]
    }
  ]
}